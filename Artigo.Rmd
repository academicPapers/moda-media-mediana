---
title: "Avaliação pela Moda, Média ou Mediana?"
author:
- Luiz Fernando Palin Droubi
- Willian Zonato
date: "`r format(Sys.Date(), '%d/%m/%Y')`"
output:
  pdf_document:
    keep_tex: yes
    number_sections: yes
  html_document:
    fig_caption: yes
    keep_md: yes
classoption: a4paper
header-includes:
- \usepackage[brazil]{babel}
- \usepackage{graphicx}
- \usepackage{float}
- \usepackage{subfig}
- \usepackage{caption}
documentclass: article
link-citations: yes
csl: ABNT_UFPR_2011-Mendeley.csl
subtitle: Estudo de Caso
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dev = "png", dpi = 600, out.width = "70%", fig.pos = "H",
                      fig.path = "images/", fig.align = "center", warning = FALSE)
options(digits = 10)
brformat <- function(x, decimal.mark = ",", big.mark = ".", digits = 2, nsmall = 2, scientific = FALSE, ...) {
  format(x, decimal.mark = decimal.mark, big.mark = big.mark, digits = digits, 
         nsmall = nsmall, scientific = scientific, ...)
}
reais <- function(prefix = "R$", ...) {
  function(x) paste(prefix, brformat(x, ...), sep = "")
}
porcento <- function (x) {
    if (length(x) == 0) 
        return(character())
    x <- plyr::round_any(x, scales:::precision(x)/100)
    paste0(x * 100, "\\%")
}
# library(appraiseR)
library(ggplot2)
```

# INTRODUÇÃO

# REVISÃO BIBLIOGRÁFICA

## Esperança matemática ou Valor Esperado

Segundo @wiki:E, a "**esperança matemática** de uma variável aleatória é a soma do produto de cada probabilidade de saída da experiência pelo seu respectivo valor. Isto é, representa o valor médio 'esperado' de uma experiência se ela for repetida muitas vezes". Matematicamente, a Esperança de uma variável aleatória $X$ é representada pelo símbolo $E[X]$, de tal forma que, pela definição dada acima, no caso de uma variável aleatória discreta:

$$E[X] = \sum_{i = 1}^{\infty}x_ip(x_i)$$

Já para uma variável aleatória contínua, o valor esperado torna-se:

$$E[X] = \int_{-\infty}^{\infty}xf(x)dx$$


## O problema da retransformação das variáveis

De acordo com Duan [-@Duan, 606], o Valor Esperado $E$ de uma variável resposta $Y$ que tenha sido transformada em valores $\eta$ durante a regressão linear por uma função $g(Y)$ **não-linear** não é igual ao valor da simples retransformação da variável transforma pela sua função inversa $h(\eta) = g^{-1}(Y)$. Em outros termos[@Duan, 606]:

$$E[Y_0] = E[h(x_0\beta + \epsilon)] \ne h(x_o\beta)$$

Numa regressão linear logaritmizada, ou seja, uma regressão linear com o logarítmo da variável dependente, para efetuar apropriadamente a retransformação das estimativas de volta a sua escala original, precisa-se ter em conta a desigualdade mencionada na seção \ref{esperanca-matematica-ou-valor-esperado}.

Segundo @NBERt0246, quando ajustamos o logaritmo natural de uma variável $Y$ contra outra variável $X$ através da seguinte equação de regressão:

$$ln(Y) = \beta_0 + \beta_1X + \epsilon$$

Sabe-se que a melhor estimativa que se pode fazer da variável dependente $Y$ é o seu Valor Esperado, que neste caso vale:

$$E[Y] = e^{\beta_0 + \beta_1X} \cdot E[e^\epsilon]$$

Embora o valor esperado dos resíduos $\epsilon$ seja igual a zero, ele está submetido a uma transformação não linear, de maneira que não podemos afirmar que $E[e^\epsilon] = 1$, como vimos na seção anterior. Desta maneira, o estimador abaixo é enviesado:

$$E[Y] = e^{\beta_0 + \beta_1X}$$

Se o termo de erro $\epsilon$ é normalmente distribuído $N(0,\sigma^2)$, então um estimador não-enviesado para o valor esperado $E[Y]$, de acordo com @Duan, assume a forma vista na equação abaixo @Duan[apud @NBERt0246, p.2 e 6]:

$$E[Y] = e^{\beta_0 + \beta_1X} \cdot e^{\frac{1}{2}\sigma^2}$$

# ESTUDO DE CASO

Neste estudo comparamos a precisão de diversos tipos de modelos estatísticos (regressão linear, regressão não-linear e modelo linear generalizado) sobre dados gerados com erros randômicos normais com média zero e desvio-padrão $\sigma = 1$.

## Geração de dados randômicos

Para a geração de dados foi utilizada a seguinte expressão teórica, dentro do intervalo $0 \leqslant x \leqslant  1$:

$$y = e^{-5x + 2}$$
Para obter alguma variabilidade, foram adicionados aos valores teóricos de $y$ erros normais $N(0;0,2)$.

```{r dados}
set.seed(123)

a = -5
b = 2

x = runif(100, 0, 1)
y = exp(a*x + b + rnorm(100, 0, .2))
```

* Gráfico dos dados gerados

```{r grafico, fig.cap = "Gráfico dos dados gerados"}
plot(x,y, pch = 16, cex = 0.5)
```


### Gráfico da variável transformada

```{r graficotrans, fig.cap = "Gráfico da variável transformada", fig.keep='last'}
plot(x, log(y), pch = 16, cex = 0.5) 
abline(lm(log(y) ~ x), col = 2)
```

## Ajuste da regressão não-linear

```{r nls}
### NLS Fit
NLfit <- nls(y ~ exp(a*x+b), start = c(a = -10, b = 15)) 
```

### Coeficientes

```{r coef}
co <- coef(NLfit)
co
```

### Gráfico do modelo não-linear

```{r graficoNL, fig.cap = "Gráfico do modelo não-linear"}
f <- function(x,a,b) {exp(a*x+b)}
curve(f(x = x, a = co[1], b = co[2]), col = 2, lwd = 1.2) 
curve(f(x = x, a = -5, b = 2), col = 3, lwd = 1.5, add = TRUE)
```

### Estimativas do modelo não-linear

```{r}
pNLfit <- predict(NLfit, newdata = data.frame(x = .7))
pNLfit
```

O valor teórico obtido pela equação original ($y = e^{-5x + 2}$) é de:

```{r}
Yteorico <- exp(-5*.7 + 2)
round(Yteorico, 4)
```

$$\epsilon = \frac{\hat{Y} - Y_{teórico}}{Y_{teórico}}$$

O valor obtido pelo modelo é muito próximo do valor teórico. O erro do modelo, portanto, é de `r porcento((pNLfit - Yteorico)/Yteorico)`.

## Ajuste de modelo linear generalizado

### Poisson

```{r glm}
Gfit <- glm(y ~ x, family = poisson())
summary(Gfit)
```

#### Estimativa com o modelo linear generalizado com Poisson

```{r}
pGfit <- predict(Gfit, newdata = data.frame(x = .7), type = "response")
pGfit
```

O valor obtido pelo modelo também é muito próximo do valor teórico obtido pela equação original ($y = e^{-5x + 2}$). Neste caso, o erro do modelo é de `r porcento((pGfit - Yteorico)/Yteorico)`.

### Gauss

```{r glm2}
Gfit2 <- glm(y ~ x, family = gaussian(link = "log"))
summary(Gfit2)
```

#### Estimativa com o modelo linear generalizado com Gauss

```{r}
pGfit2 <- predict(Gfit2, newdata = data.frame(x = .7), type = "response")
pGfit2
```

O valor obtido pelo modelo também é muito próximo do valor teórico obtido pela equação original ($y = e^{-5x + 2}$). Neste caso, o erro do modelo é de `r porcento((pGfit2 - Yteorico)/Yteorico)`. Observar que a adoção de ajuste por modelo linear generalizado com família gaussiana e *log-link* é equivalente ao ajustamento de um modelo de regressão não-linear, como visto na seção anterior.

## Ajuste de Regressão Linear com variável dependente transformada

```{r lm}
### LM Fit
fit <- lm(log(y) ~ x)
s <- summary(fit)
s
```

### Gráfico do modelo linear

```{r graficoFIT, fig.cap = "Gráfico do modelo linear"}
#plotmod(fit)
```


### Estimativas

a. Pela mediana

```{r mediana}
Y <- predict(fit, newdata = data.frame(x = .7))
p_mediana <- exp(Y)
p_mediana
```

O erro do modelo, neste caso, é de `r porcento((p_mediana - Yteorico)/Yteorico)`.

b. Pela moda

```{r moda}
p_moda <- exp(Y - s$sigma^2)
p_moda
```

O erro do modelo, neste caso, é de `r porcento((p_moda - Yteorico)/Yteorico)`.

c. Pela média

```{r media}
p_media <- exp(Y + s$sigma^2/2)
p_media
```

O erro do modelo, neste caso, é de `r porcento((p_media - Yteorico)/Yteorico)`.

## Comparação dos resultados obtidos

| Modelo                | Previsão                    | Erro (%)                                    | 
|:----------------------|----------------------------:|--------------------------------------------:|
| **Valor Teórico**     | **`r round(Yteorico, 4)`**  | ------                                      |
| Regressão Não-Linear  | `r round(pNLfit, 4)`        |`r porcento((pNLfit-Yteorico)/Yteorico)`     |
| GLM (Poisson)         | `r round(pGfit, 4)`         |`r porcento((pGfit-Yteorico)/Yteorico)`      |
| GLM (Gauss)           | `r round(pGfit2, 4)`        |`r porcento((pGfit2-Yteorico)/Yteorico)`     |
| LM (Mediana)          | `r round(p_mediana, 4)`     |`r porcento((p_mediana-Yteorico)/Yteorico)`  |
| LM (Moda)             | `r round(p_moda, 4)`        |`r porcento((p_moda-Yteorico)/Yteorico)`     |
| LM (Média)            | `r round(p_media, 4)`       |`r porcento((p_media-Yteorico)/Yteorico)`    |

# Método de Monte-Carlo

O resultados acima não devem ser interpretados como taxativos, pois os valores encontrados foram obtidos de dados gerados randômicamente.

Para uma comparação mais precisa entre os modelos testados, utilizamos o método de Monte Carlo, simulando os dados randomicamente a cada iteração. Finalmente, comparamos o valor médio obtido por cada cada modelo ao valor téorico.

```{r, cache = TRUE}
Nsim <- 500
pNL <- vector(mode = "numeric", length = Nsim)
pG <- vector(mode = "numeric", length = Nsim)
pG2 <- vector(mode = "numeric", length = Nsim)
p_mediana <- vector(mode = "numeric", length = Nsim)
p_moda <- vector(mode = "numeric", length = Nsim)
p_media <- vector(mode = "numeric", length = Nsim)
for (i in 1:Nsim) {
  y = exp(a*x + b + rnorm(100, 0, .2))
  NLfit <- nls(y ~ exp(a*x+b), start = c(a = -10, b = 15)) 
  Gfit <- glm(y ~ x, family = poisson())
  Gfit2 <- glm(y ~ x, family = gaussian(link = "log"))
  fit <- lm(log(y) ~ x)
  s <- summary(fit)
  pNL[i] <- predict(NLfit, newdata = data.frame(x = .7))
  pG[i] <- predict(Gfit, newdata = data.frame(x = .7), type = "response")
  pG2[i] <- predict(Gfit2, newdata = data.frame(x = .7), type = "response")
  p_mediana[i] <- exp(predict(fit, newdata = data.frame(x = .7)))
  p_moda[i] <- exp(predict(fit, newdata = data.frame(x = .7)) - s$sigma^2)
  p_media[i] <- exp(predict(fit, newdata = data.frame(x = .7)) + s$sigma^2/2)
}
```

* Gráficos

```{r histogramas, out.width="100%", echo = FALSE, message=FALSE, fig.cap = "Histogramas das variáveis simuladas"}
data <- data.frame(pNL, pG, pG2, p_mediana, p_moda, p_media)
p <- list()
p[[1]] <- ggplot(data, aes(x = pNL), breaks = 10) + 
  geom_histogram(aes(y = ..density..)) + 
  stat_density(geom = "line", aes(colour = "Kernel")) +
  stat_function(fun = dnorm,
                args = list(mean = mean(data$pNL), sd = sd(data$pNL)), 
                aes(colour = "Normal")) + 
  theme(legend.position = "bottom", legend.title = element_blank(),
        legend.text = element_text(size = 8))
p[[2]] <- ggplot(data, aes(x = pG), breaks = 10) + 
  geom_histogram(aes(y = ..density..)) + 
  stat_density(geom = "line", aes(colour = "Kernel")) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$pG), sd = sd(data$pG)), 
                aes(colour = "Normal")) + 
  theme(legend.position = "bottom", legend.title = element_blank(),
        legend.text = element_text(size = 8))
p[[3]] <- ggplot(data, aes(x = pG2), breaks = 10) + 
  geom_histogram(aes(y = ..density..)) + 
  stat_density(geom = "line", aes(colour = "Kernel")) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$pG2), sd = sd(data$pG2)), 
                aes(colour = "Normal")) + 
  theme(legend.position = "bottom", legend.title = element_blank(),
        legend.text = element_text(size = 8))
p[[4]] <- ggplot(data, aes(x = p_mediana), breaks = 10) + 
  geom_histogram(aes(y = ..density..)) + 
  stat_density(geom = "line", aes(colour = "Kernel")) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$p_mediana), sd = sd(data$p_mediana)), 
                aes(colour = "Normal")) + 
  theme(legend.position = "bottom", legend.title = element_blank(),
        legend.text = element_text(size = 8))
p[[5]] <- ggplot(data, aes(x = p_moda), breaks = 10) + 
  geom_histogram(aes(y = ..density..)) + 
  stat_density(geom = "line", aes(colour = "Kernel")) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$p_moda), sd = sd(data$p_moda)), 
                aes(colour = "Normal")) + 
  theme(legend.position = "bottom", legend.title = element_blank(),
        legend.text = element_text(size = 8))
p[[6]] <- ggplot(data, aes(x = p_media), breaks = 10) + 
  geom_histogram(aes(y = ..density..)) + 
  stat_density(geom = "line", aes(colour = "Kernel")) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$p_media), sd = sd(data$p_media)), 
                aes(colour = "Normal")) + 
  theme(legend.position = "bottom", legend.title = element_blank(),
        legend.text = element_text(size = 8))
cowplot::plot_grid(plotlist = p, ncol = 3)
```


| Modelo                |Previsão                     |$\sigma^2$                  |Erro                   |     
|:----------------------|----------------------------:|---------------------------:|----------------------:|   
| **Valor Teórico**     |**`r round(Yteorico, 4)`**   |------                      |------                 |   
| Regressão Não-Linear  |`r round(mean(pNL), 4)`      |`r round(sd(pNL), 4)`       |`r porcento((mean(pNL)-Yteorico)/Yteorico)`       |  
| GLM (Poisson)         |`r round(mean(pG), 4)`       |`r round(sd(pG), 4)`        |`r porcento((mean(pG)-Yteorico)/Yteorico)`        |  
| GLM (Gauss)           |`r round(mean(pG2), 4)`      |`r round(sd(pG2), 4)`       |`r porcento((mean(pG2)-Yteorico)/Yteorico)`       |  
| LM (Mediana)          |`r round(mean(p_mediana), 4)`|`r round(sd(p_mediana), 4)` |`r porcento((mean(p_mediana)-Yteorico)/Yteorico)` |  
| LM (Moda)             |`r round(mean(p_moda), 4)`   |`r round(sd(p_moda), 4)`    |`r porcento((mean(p_moda)-Yteorico)/Yteorico)`    |  
| LM (Média)            |`r round(mean(p_media), 4)`  |`r round(sd(p_media), 4)`   |`r porcento((mean(p_media)-Yteorico)/Yteorico)`   |    

# REFERÊNCIAS {-}